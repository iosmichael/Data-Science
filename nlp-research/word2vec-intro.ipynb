{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Word Embedding Models\n",
    "\n",
    "**Word2Vec** (Most widely used word embedding models)\n",
    "* https://code.google.com/archive/p/word2vec/\n",
    "\n",
    "**GloVe**\n",
    "* http://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "**Difference between Word2Vec and GloVe**\n",
    "word2vec is a \"predictive\" model, whereas GloVe is a \"count-based\" model. Predictive models learn their vectors in order to improve their predictive ability of Loss **(target word|context words; vectors)**. In word2vec, this is cast as a feed-forward neural network and optimized as such using SGD. Count-based models learn their vetors by essentially doing dimensionality reduction on the co-occurrence counts matrix. The counts matrix in the case of GloVe is preprocessed by normalizing the counts and log-smoothing them. This greatly improves the quality of the learned representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Google-News Pretrained Word2Vec Model\n",
    "\n",
    "**Code using gensim**\n",
    "``` python\n",
    "word_model = gensim.models.Word2Vec(sentences, size=100, min_count=1, \n",
    "                                    window=5, iter=100)\n",
    "pretrained_weights = word_model.wv.syn0\n",
    "vocab_size, emdedding_size = pretrained_weights.shape\n",
    "print('Result embedding shape:', pretrained_weights.shape)\n",
    "print('Checking similar words:')\n",
    "for word in ['model', 'network', 'train', 'learn']:\n",
    "  most_similar = ', '.join('%s (%.2f)' % (similar, dist) \n",
    "                           for similar, dist in word_model.most_similar(word)[:8])\n",
    "  print('  %s -> %s' % (word, most_similar))\n",
    "\n",
    "def word2idx(word):\n",
    "  return word_model.wv.vocab[word].index\n",
    "def idx2word(idx):\n",
    "  return word_model.wv.index2word[idx]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
